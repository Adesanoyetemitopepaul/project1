{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d656ff2e-7ca3-4fcc-b367-90a305e8fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from IPython.display import VimeoVideo\n",
    "from ipywidgets import interact\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59625f2-fee2-4ae2-9a3c-07217b9601f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb = pd.read_excel(r\"C:\\Users\\User\\banckrucpcy in poland/bankruptcy-in-poland project 5 (Recovered).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c26e76-2c3a-4f1a-95b0-2af15ac3aef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "      <th>bankrupt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.146240</td>\n",
       "      <td>0.46038</td>\n",
       "      <td>0.28230</td>\n",
       "      <td>1.62940</td>\n",
       "      <td>2.59520</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171850</td>\n",
       "      <td>1.17210</td>\n",
       "      <td>1.60180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027516</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.90108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.98820</td>\n",
       "      <td>4.11030</td>\n",
       "      <td>102.19000</td>\n",
       "      <td>3.57160</td>\n",
       "      <td>5.95000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.22612</td>\n",
       "      <td>0.48839</td>\n",
       "      <td>3.15990</td>\n",
       "      <td>84.87400</td>\n",
       "      <td>0.19114</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>2.98810</td>\n",
       "      <td>1.00770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.99236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.77420</td>\n",
       "      <td>3.79220</td>\n",
       "      <td>64.84600</td>\n",
       "      <td>5.62870</td>\n",
       "      <td>4.45810</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.188290</td>\n",
       "      <td>0.41504</td>\n",
       "      <td>0.34231</td>\n",
       "      <td>1.92790</td>\n",
       "      <td>-58.27400</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.233580</td>\n",
       "      <td>1.40940</td>\n",
       "      <td>1.33930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176480</td>\n",
       "      <td>0.321880</td>\n",
       "      <td>0.82635</td>\n",
       "      <td>0.073039</td>\n",
       "      <td>2.59120</td>\n",
       "      <td>7.07560</td>\n",
       "      <td>100.54000</td>\n",
       "      <td>3.63030</td>\n",
       "      <td>4.63750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.182060</td>\n",
       "      <td>0.55615</td>\n",
       "      <td>0.32191</td>\n",
       "      <td>1.60450</td>\n",
       "      <td>16.31400</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.182060</td>\n",
       "      <td>0.79808</td>\n",
       "      <td>1.81260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555770</td>\n",
       "      <td>0.410190</td>\n",
       "      <td>0.46957</td>\n",
       "      <td>0.029421</td>\n",
       "      <td>8.45530</td>\n",
       "      <td>3.34880</td>\n",
       "      <td>107.24000</td>\n",
       "      <td>3.40360</td>\n",
       "      <td>12.45400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id    feat_1   feat_2   feat_3   feat_4    feat_5   feat_6  \\\n",
       "0           1  0.174190  0.17419  0.17419  0.17419   0.17419  0.17419   \n",
       "1           2  0.146240  0.46038  0.28230  1.62940   2.59520  0.00000   \n",
       "2           3  0.000595  0.22612  0.48839  3.15990  84.87400  0.19114   \n",
       "3           5  0.188290  0.41504  0.34231  1.92790 -58.27400  0.00000   \n",
       "4           6  0.182060  0.55615  0.32191  1.60450  16.31400  0.00000   \n",
       "\n",
       "     feat_7   feat_8   feat_9  ...   feat_56   feat_57  feat_58   feat_59  \\\n",
       "0  0.174190  0.17419  0.17419  ...  0.174190  0.174190  0.17419  0.174190   \n",
       "1  0.171850  1.17210  1.60180  ...  0.027516  0.271000  0.90108  0.000000   \n",
       "2  0.004572  2.98810  1.00770  ...  0.007639  0.000881  0.99236  0.000000   \n",
       "3  0.233580  1.40940  1.33930  ...  0.176480  0.321880  0.82635  0.073039   \n",
       "4  0.182060  0.79808  1.81260  ...  0.555770  0.410190  0.46957  0.029421   \n",
       "\n",
       "   feat_60  feat_61    feat_62  feat_63   feat_64  bankrupt  \n",
       "0  0.17419  0.17419    0.17419  0.17419   0.17419     False  \n",
       "1  5.98820  4.11030  102.19000  3.57160   5.95000     False  \n",
       "2  6.77420  3.79220   64.84600  5.62870   4.45810     False  \n",
       "3  2.59120  7.07560  100.54000  3.63030   4.63750     False  \n",
       "4  8.45530  3.34880  107.24000  3.40360  12.45400      True  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697f3a23-beef-4875-811f-584ea2d928cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (33, 65)\n",
      "y shape: (33,)\n"
     ]
    }
   ],
   "source": [
    "#Task 5.4.2: Create your feature matrix X and target vector y. Your target is \"bankrupt\".\n",
    "target = \"bankrupt\"\n",
    "X = dfb.drop(columns=[target])\n",
    "y = dfb[target]\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be228a28-97e0-4f7c-8a8d-1710a915dc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (26, 65)\n",
      "y_train shape: (26,)\n",
      "X_test shape: (7, 65)\n",
      "y_test shape: (7,)\n"
     ]
    }
   ],
   "source": [
    "#Task 5.4.3: Divide your data (X and y) into training and test sets using a randomized train-test split. Your test set should be 20% of your total data. And don't forget to set a random_state for reproducibility.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5962e73-c1eb-4f7a-add0-c12cd51194ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_over shape: (42, 65)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_55</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0.029986</td>\n",
       "      <td>0.79448</td>\n",
       "      <td>-0.014255</td>\n",
       "      <td>0.97797</td>\n",
       "      <td>-39.99600</td>\n",
       "      <td>-0.119500</td>\n",
       "      <td>0.029986</td>\n",
       "      <td>0.21561</td>\n",
       "      <td>1.08400</td>\n",
       "      <td>...</td>\n",
       "      <td>-1765.40000</td>\n",
       "      <td>0.077483</td>\n",
       "      <td>0.17505</td>\n",
       "      <td>0.92252</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>11.68600</td>\n",
       "      <td>1.69140</td>\n",
       "      <td>253.41000</td>\n",
       "      <td>1.44030</td>\n",
       "      <td>2.53980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>0.081951</td>\n",
       "      <td>0.24608</td>\n",
       "      <td>0.312730</td>\n",
       "      <td>3.56540</td>\n",
       "      <td>29.45000</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>0.094949</td>\n",
       "      <td>3.06380</td>\n",
       "      <td>1.11170</td>\n",
       "      <td>...</td>\n",
       "      <td>23101.00000</td>\n",
       "      <td>0.100510</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.89949</td>\n",
       "      <td>0.164700</td>\n",
       "      <td>4.02450</td>\n",
       "      <td>7.24490</td>\n",
       "      <td>52.02200</td>\n",
       "      <td>7.01630</td>\n",
       "      <td>1.51290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "      <td>0.17419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.182060</td>\n",
       "      <td>0.55615</td>\n",
       "      <td>0.321910</td>\n",
       "      <td>1.60450</td>\n",
       "      <td>16.31400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182060</td>\n",
       "      <td>0.79808</td>\n",
       "      <td>1.81260</td>\n",
       "      <td>...</td>\n",
       "      <td>2080.60000</td>\n",
       "      <td>0.555770</td>\n",
       "      <td>0.41019</td>\n",
       "      <td>0.46957</td>\n",
       "      <td>0.029421</td>\n",
       "      <td>8.45530</td>\n",
       "      <td>3.34880</td>\n",
       "      <td>107.24000</td>\n",
       "      <td>3.40360</td>\n",
       "      <td>12.45400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0.093880</td>\n",
       "      <td>0.24891</td>\n",
       "      <td>0.374170</td>\n",
       "      <td>2.50320</td>\n",
       "      <td>35.00600</td>\n",
       "      <td>0.084199</td>\n",
       "      <td>-0.089098</td>\n",
       "      <td>3.00210</td>\n",
       "      <td>0.92569</td>\n",
       "      <td>...</td>\n",
       "      <td>8843.10000</td>\n",
       "      <td>-0.080281</td>\n",
       "      <td>-0.12563</td>\n",
       "      <td>1.08030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.02740</td>\n",
       "      <td>7.09320</td>\n",
       "      <td>59.90400</td>\n",
       "      <td>6.09310</td>\n",
       "      <td>4.02380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id    feat_1   feat_2    feat_3   feat_4    feat_5    feat_6  \\\n",
       "0          23  0.029986  0.79448 -0.014255  0.97797 -39.99600 -0.119500   \n",
       "1          14  0.081951  0.24608  0.312730  3.56540  29.45000  0.011692   \n",
       "2           1  0.174190  0.17419  0.174190  0.17419   0.17419  0.174190   \n",
       "3           6  0.182060  0.55615  0.321910  1.60450  16.31400  0.000000   \n",
       "4          18  0.093880  0.24891  0.374170  2.50320  35.00600  0.084199   \n",
       "\n",
       "     feat_7   feat_8   feat_9  ...      feat_55   feat_56  feat_57  feat_58  \\\n",
       "0  0.029986  0.21561  1.08400  ...  -1765.40000  0.077483  0.17505  0.92252   \n",
       "1  0.094949  3.06380  1.11170  ...  23101.00000  0.100510  0.10870  0.89949   \n",
       "2  0.174190  0.17419  0.17419  ...      0.17419  0.174190  0.17419  0.17419   \n",
       "3  0.182060  0.79808  1.81260  ...   2080.60000  0.555770  0.41019  0.46957   \n",
       "4 -0.089098  3.00210  0.92569  ...   8843.10000 -0.080281 -0.12563  1.08030   \n",
       "\n",
       "    feat_59   feat_60  feat_61    feat_62  feat_63   feat_64  \n",
       "0  0.859700  11.68600  1.69140  253.41000  1.44030   2.53980  \n",
       "1  0.164700   4.02450  7.24490   52.02200  7.01630   1.51290  \n",
       "2  0.174190   0.17419  0.17419    0.17419  0.17419   0.17419  \n",
       "3  0.029421   8.45530  3.34880  107.24000  3.40360  12.45400  \n",
       "4  0.000000   7.02740  7.09320   59.90400  6.09310   4.02380  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resample\n",
    "#Task 5.4.4: Create a new feature matrix X_train_over and target vector y_train_over by performing random over-sampling on the training data.\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\n",
    "print(\"X_train_over shape:\", X_train_over.shape)\n",
    "X_train_over.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71d2a70b-e406-470c-a912-569daa7aef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.8077\n"
     ]
    }
   ],
   "source": [
    "#Build Model\n",
    "#Baseline\n",
    "#Task 5.4.5: Calculate the baseline accuracy score for your model.\n",
    "acc_baseline = y_train.value_counts(normalize=True).max()\n",
    "print(\"Baseline Accuracy:\", round(acc_baseline, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9337965-f579-41d4-aa1a-b42c55c3023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate\n",
    "#Even though the building blocks are the same, here's where we start working with something new. First, we're going to use a new type of ensemble model for our classifier.\n",
    "clf = make_pipeline(SimpleImputer(), GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a68d0045-1682-4780-96aa-245cf3826182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember while we're doing this that we only want to be looking at the positive class. Here, the positive class is the one where the companies really did go bankrupt. In the dictionary we made last time, the positive class is made up of the companies with the bankrupt: true key-value pair.\n",
    "\n",
    "#Next, we're going to tune some of the hyperparameters for our model.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "292834de-bbd9-4448-a615-e5ad55f328c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simpleimputer__strategy': ['mean', 'median'],\n",
       " 'gradientboostingclassifier__n_estimators': range(20, 31, 5),\n",
       " 'gradientboostingclassifier__max_depth': range(2, 5)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task 5.4.7: Create a dictionary with the range of hyperparameters that we want to evaluate for our classifier.\n",
    "\n",
    "#For the SimpleImputer, try both the \"mean\" and \"median\" strategies.\n",
    "#For the GradientBoostingClassifier, try max_depth settings between 2 and 5.\n",
    "#Also for the GradientBoostingClassifier, try n_estimators settings between 20 and 31, by steps of 5.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"simpleimputer__strategy\":[\"mean\", \"median\"],\n",
    "    \"gradientboostingclassifier__n_estimators\" : range(20,31,5),\n",
    "    \"gradientboostingclassifier__max_depth\": range(2,5)\n",
    "    \n",
    "}\n",
    "params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Note that we're trying much smaller numbers of n_estimators. \n",
    "#This is because GradientBoostingClassifier is slower to train than the RandomForestClassifier. \n",
    "#You can try increasing the number of estimators to see if model performance improves, but keep in mind that you could be waiting a long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a12e57a9-42b8-4e22-84af-f128c620ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 5.4.8: Create a GridSearchCV named model that includes your classifier and hyperparameter grid. \n",
    "#Be sure to use the same arguments for cv and n_jobs that you used above, and set verbose to 1.\n",
    "\n",
    "model = GridSearchCV(clf, param_grid=params,cv=5, n_jobs =-1, verbose=1)\n",
    "\n",
    "\n",
    "#Now that we have everything we need for the model, let's fit it to the data and see what we've got.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d60e80b-0da3-4759-8bfe-9ff5ac5bf786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "#Task 5.4.9: Fit your model to the over-sampled training data.\n",
    "\n",
    "# Fit model to over-sampled training data\n",
    "model.fit(X_train_over, y_train_over)\n",
    "\n",
    "##input strategy = 2\n",
    "#N-ESTIMATOR=3\n",
    "#MAX DEPTH=3\n",
    "#CV=5\n",
    "#N estimator is the number of tree to use in machine learning\n",
    "\n",
    "TOTAL=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07a5e810-1b37-4bff-acef-c1ba3a4f686f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gradientboostingclassifier__max_depth</th>\n",
       "      <th>param_gradientboostingclassifier__n_estimators</th>\n",
       "      <th>param_simpleimputer__strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.084999</td>\n",
       "      <td>2.283804e-02</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 2, '...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.062496</td>\n",
       "      <td>7.599534e-07</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>median</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 4, '...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.062495</td>\n",
       "      <td>6.675720e-07</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 4, '...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.055802</td>\n",
       "      <td>6.421239e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>median</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 4, '...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.051017</td>\n",
       "      <td>7.658024e-03</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 4, '...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.065896</td>\n",
       "      <td>4.629674e-03</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>median</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 3, '...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.071106</td>\n",
       "      <td>7.367429e-03</td>\n",
       "      <td>0.011541</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 3, '...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.062496</td>\n",
       "      <td>9.882193e-03</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>median</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 3, '...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.059370</td>\n",
       "      <td>6.249332e-03</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 3, '...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.056247</td>\n",
       "      <td>7.653818e-03</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>median</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 3, '...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.084999  2.283804e-02         0.005102        0.004451   \n",
       "15       0.062496  7.599534e-07         0.006250        0.007654   \n",
       "14       0.062495  6.675720e-07         0.003125        0.006249   \n",
       "13       0.055802  6.421239e-03         0.000000        0.000000   \n",
       "12       0.051017  7.658024e-03         0.006251        0.007656   \n",
       "11       0.065896  4.629674e-03         0.009841        0.008080   \n",
       "10       0.071106  7.367429e-03         0.011541        0.006769   \n",
       "9        0.062496  9.882193e-03         0.009375        0.007655   \n",
       "8        0.059370  6.249332e-03         0.006250        0.007654   \n",
       "7        0.056247  7.653818e-03         0.006250        0.007654   \n",
       "\n",
       "   param_gradientboostingclassifier__max_depth  \\\n",
       "0                                            2   \n",
       "15                                           4   \n",
       "14                                           4   \n",
       "13                                           4   \n",
       "12                                           4   \n",
       "11                                           3   \n",
       "10                                           3   \n",
       "9                                            3   \n",
       "8                                            3   \n",
       "7                                            3   \n",
       "\n",
       "   param_gradientboostingclassifier__n_estimators  \\\n",
       "0                                              20   \n",
       "15                                             25   \n",
       "14                                             25   \n",
       "13                                             20   \n",
       "12                                             20   \n",
       "11                                             30   \n",
       "10                                             30   \n",
       "9                                              25   \n",
       "8                                              25   \n",
       "7                                              20   \n",
       "\n",
       "   param_simpleimputer__strategy  \\\n",
       "0                           mean   \n",
       "15                        median   \n",
       "14                          mean   \n",
       "13                        median   \n",
       "12                          mean   \n",
       "11                        median   \n",
       "10                          mean   \n",
       "9                         median   \n",
       "8                           mean   \n",
       "7                         median   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'gradientboostingclassifier__max_depth': 2, '...           0.666667   \n",
       "15  {'gradientboostingclassifier__max_depth': 4, '...           0.666667   \n",
       "14  {'gradientboostingclassifier__max_depth': 4, '...           0.666667   \n",
       "13  {'gradientboostingclassifier__max_depth': 4, '...           0.666667   \n",
       "12  {'gradientboostingclassifier__max_depth': 4, '...           0.666667   \n",
       "11  {'gradientboostingclassifier__max_depth': 3, '...           0.666667   \n",
       "10  {'gradientboostingclassifier__max_depth': 3, '...           0.666667   \n",
       "9   {'gradientboostingclassifier__max_depth': 3, '...           0.666667   \n",
       "8   {'gradientboostingclassifier__max_depth': 3, '...           0.666667   \n",
       "7   {'gradientboostingclassifier__max_depth': 3, '...           0.666667   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.888889              0.875                1.0   \n",
       "15           0.888889              0.875                1.0   \n",
       "14           0.888889              0.875                1.0   \n",
       "13           0.888889              0.875                1.0   \n",
       "12           0.888889              0.875                1.0   \n",
       "11           0.888889              0.875                1.0   \n",
       "10           0.888889              0.875                1.0   \n",
       "9            0.888889              0.875                1.0   \n",
       "8            0.888889              0.875                1.0   \n",
       "7            0.888889              0.875                1.0   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                 1.0         0.886111        0.121843                1  \n",
       "15                1.0         0.886111        0.121843                1  \n",
       "14                1.0         0.886111        0.121843                1  \n",
       "13                1.0         0.886111        0.121843                1  \n",
       "12                1.0         0.886111        0.121843                1  \n",
       "11                1.0         0.886111        0.121843                1  \n",
       "10                1.0         0.886111        0.121843                1  \n",
       "9                 1.0         0.886111        0.121843                1  \n",
       "8                 1.0         0.886111        0.121843                1  \n",
       "7                 1.0         0.886111        0.121843                1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task 5.4.10: Extract the cross-validation results from model and load them into a DataFrame named cv_results.\n",
    "results = pd.DataFrame(model.cv_results_)\n",
    "results.sort_values(\"rank_test_score\").head(10)\n",
    "\n",
    "#results.sort_values(\"rank_test_score\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b28c9742-f8bf-46c7-8662-b4e567a899d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE MEAN TEST SCORE OF GRADE ONE HERE WHEN COMPARE TO THAT OF THE RANDOM FOREST IS VERY HIGH( I.E IT PERFORM LESS BETTER)\n",
    "#THAT DOES NOT MEAN THE MODEL( I.E GRADIENT BOOSTER) IS BAD BUT IT DOES MEAN BECAUSE WE ARE LOOKING OVER SMALL HYPERPARAMETER SPACE WE CANT QUITE MAYBE LOOK AT ALL THE RIGHT SETTING THAT WILL GIVE US THE BEST PERFORMANCE\n",
    "#OR IT MAY MEAN THAT OUR  THIS MODEL IS NOT GOOD WHICH IS WHY WE TRY DIFFERENT MODEL FOR DIFFERENT SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fc0e7cf-35c7-4088-b6fd-e32cb4cabfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gradientboostingclassifier__max_depth': 2,\n",
       " 'gradientboostingclassifier__n_estimators': 20,\n",
       " 'simpleimputer__strategy': 'mean'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are quite a few hyperparameters there, so let's pull out the ones that work best for our model.\n",
    "#Task 5.4.11: Extract the best hyperparameters from model.\n",
    "# Extract best hyperparameters\n",
    "\n",
    "model.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53827cec-05b3-4da4-b7bd-f46ff267adcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "#Now that we have a working model that's actually giving us something useful, let's see how good it really is.\n",
    "\n",
    "#Task 5.4.12: Calculate the training and test accuracy scores for model.\n",
    "\n",
    "acc_train = model.score(X_train, y_train)\n",
    "acc_test = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Training Accuracy:\", round(acc_train, 4))\n",
    "print(\"Validation Accuracy:\", round(acc_test, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be832880-405f-4f8e-8dbb-e48de6881adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Just like before, let's make a confusion matrix to see how our model is making its correct and incorrect predictions.\n",
    "\n",
    "#Task 5.4.13: Plot a confusion matrix that shows how your best model performs on your test set.\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test,y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44eb1578-7732-4b89-9ac1-33fb24231f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This matrix is a great reminder of how imbalanced our data is, and of why accuracy isn't always the best metric for judging whether or not a model is giving us what we want. \n",
    "#After all, if 95% of the companies in our dataset didn't go bankrupt, all the model has to do is always predict {\"bankrupt\": False}, and it'll be right 95% of the time. \n",
    "#The accuracy score will be amazing, but it won't tell us what we really need to know.\n",
    "\n",
    "#Instead, we can evaluate our model using two new metrics: precision and recall.\n",
    "#The precision score is important when we want our model to only predict that a company will go bankrupt if its very confident in its prediction.\n",
    "#The recall score is important if we want to make sure to identify all the companies that will go bankrupt, even if that means being incorrect sometimes.\n",
    "\n",
    "#Let's start with a report you can create with scikit-learn to calculate both metrics. \n",
    "#Then we'll look at them one-by-one using a visualization tool we've built especially for the Data Science Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55f9c382-5af3-46b6-ac0a-c738579edbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91         5\n",
      "        True       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.92      0.75      0.79         7\n",
      "weighted avg       0.88      0.86      0.84         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Task 5.4.14: Print the classification report for your model, using the test set.\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74df487c-65a5-4203-ad4d-290c1136d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    " #THE SUPPORT  TELL US HOW MANY OBSERVATION ARE IN THE DATA SET AND THE HOW MANY  OBSERVATION USE TO CALCULATE  A PATRICULAR METRIC FOR EACH OF THE ROW\n",
    "#THAT IS,\n",
    "# THE ACCURACY WAS O.86(86%) CALCULATED WITH 7 OBSERVATION\n",
    "#FALSE(OUR COMPANY WILL NOT GO BANKRUPT) THE NUMBER OF OBSERVATION IN IT IS  5 OBSERVATION\n",
    "#TRUE (OUR COMPANY GO BANKRUPT) THE THE NUMBER OF OBSERVATION IN IT IS 2 OBSERVATION\n",
    "\n",
    "#PRECISION AND RECAL HAS TWO VALUE EACH\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76a0053e-58bd-4c66-9a2a-01af1c265c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RECALL\n",
    "\n",
    "#The recall score is important if we want to make sure to identify all the companies that will go bankrupt, even if that means being incorrect sometimes.\n",
    "#recall measure how well your model identify observation that belong to the positive class\n",
    "#high recal score means we want to get high number of company. the best recal score is 1 and the worse is 0. \n",
    "#what does it means as regardt to yhis project it means of all our company going bankrupt what fraction did our model predict that its actuall going bankrupt\n",
    "# if it is 1 our model succesfully identify all companies going bankrupt if it is 0 it does not identify any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9f525bc-dfc0-4156-aede-3741179d2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code did not run because it was perculiar to them looking for a code to run it\n",
    "\n",
    "#c= ConfusionMatrixWidget(model, X_test, y_test)\n",
    "#c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e4dff36-e58d-4112-9905-360bf5b22ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2321a75-eea5-4a57-a625-67bd4a37ded4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9344864, 0.0655136, 0.0655136, 0.0655136, 0.0655136])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)[:5, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0004a0a-0f6a-4976-9e54-84bd57b32448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: below 0.5 not bankrupt above it is bankrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "063e0be8-a472-4fe2-aff5-0001a3a4c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRECISION: THIS MEASURE HOW WELL OUR MODEL IDENTIFY OBSERVATION BELONGING TO THE POSITIVE CLASS WITHOUT MAKING ERROR OF FALSE POSITIVE, thatis company that really go bankrupt.\n",
    "\n",
    "#RECAL CATCH THEM ALL PRECISON MAKES THE RIGHT DECISION\n",
    "\n",
    "#THE BEST IS 1 AND WORSE O\n",
    "\n",
    "#WHAT DOES IT MEANS TO OUR MODEL? IT MEANS THAT OF ALL THE COMPANY IN OUR TEST SET THAT THE MODEL PREDICT THAT IT WOULD GO BANKRUPT PRECISION IS THE FRACTION THAT ACTUALLY WENT BANKRUPT\n",
    "\n",
    "#ONE OF THE QUESTION TO ASK IS WHICH ONE SHOULD WE FAVOUR BETWEEN RECAL AND PRECISION? THIS DEPEND ON THE TYPE OF PROJECT\n",
    "\n",
    "#If you move the probability threshold, you can see that there's a tradeoff between precision and recall. That is, as one gets better, the other suffers. As a data scientist, you'll often need to decide whether you want a model with better precision or better recall. What you choose will depend on how to intend to use your model.\n",
    "\n",
    "#Let's look at two examples, one where recall is the priority and one where precision is more important. First, let's say you work for a regulatory agency in the European Union that assists companies and investors navigate insolvency proceedings. You want to build a model to predict which companies could go bankrupt so that you can send debtors information about filing for legal protection before their company becomes insolvent. The administrative costs of sending information to a company is â‚¬500. The legal costs to the European court system if a company doesn't file for protection before bankruptcy is â‚¬50,000.\n",
    "\n",
    "#For a model like this, we want to focus on recall, because recall is all about quantity. A model that prioritizes recall will cast the widest possible net, which is the way to approach this problem. We want to send information to as many potentially-bankrupt companies as possible, because it costs a lot less to send information to a company that might not become insolvent than it does to skip a company that does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "475ca5bc-b160-4988-88e8-265b917efb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the second example, let's say we work at a private equity firm that purchases distressed businesses, improve them, and then sells them for a profit. \n",
    "#You want to build a model to predict which companies will go bankrupt so that you can purchase them ahead of your competitors. If the firm purchases a company that is indeed insolvent, it can make a profit of â‚¬100 million or more. But if it purchases a company that isn't insolvent and can't be resold at a profit, the firm will lose â‚¬250 million.\n",
    "\n",
    "#For a model like this, we want to focus on precision. \n",
    "#If we're trying to maximize our profit, the quality of our predictions is much more important than the quantity of our predictions. It's not a big deal if we don't catch every single insolvent company, but it's definitely a big deal if the companies we catch don't end up becoming insolvent.\n",
    "\n",
    "#This time we're going to build the visualization together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec98e785-dacf-4377-9402-8fcbf403190b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ccd75049a94899885bdad0f78190b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='threshold', max=1.0, step=0.05), Output()), _dom_claâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Task 5.4.17: Create an interactive dashboard that shows how company profit and losses change in relationship to your model's probability threshold. Start with the make_cnf_matrix function, which should calculate and print profit/losses, and display a confusion matrix. Then create a FloatSlider thresh_widget that ranges from 0 to 1. Finally combine your function and slider in the interact function.\n",
    "\n",
    "def make_cnf_matrix(threshold):\n",
    "    \n",
    "    y_pred_proba=model.predict_proba(X_test)[:, -1]\n",
    "    y_pred=y_pred_proba> threshold\n",
    "    conf_matrix= confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp= conf_matrix.ravel()\n",
    "    print(f\"profit:â‚¬{tp* 100_000_000}\")\n",
    "    print(f\"losses:â‚¬{fp* 100_000_000}\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, colorbar=False)\n",
    "\n",
    "thresh_widget = widgets.FloatSlider(min=0, max=1, value=0.5, step=0.05)\n",
    "\n",
    "interact(make_cnf_matrix, threshold=thresh_widget);\n",
    "\n",
    "\n",
    "#tn, fp, fn, tp =  true negative, false positive, false negative, true positive\n",
    "#tp ==== precision\n",
    "#fp  ==== recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f0eb0ee-dfcb-4ca1-b125-058159fbc27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Communicate\n",
    "#Almost there! Save the best model so we can share it with other people, then put it all together with what we learned in the last lesson.\n",
    "\n",
    "#Task 5.4.18: Using a context manager, save your best-performing model to a file named \"model-5-4.pkl\".\n",
    "\n",
    "# Save model\n",
    "with open(\"model-5-4.pkl\",\"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "202bbe2d-c95b-48b5-a989-f92442cac7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "4.4.19 does not work because it is using json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "414af8a3-e587-4934-9d0d-4d588e48a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 5.4.20: Import your make_predictions function from your my_predictor module, and use the code below to make sure it works as expected. Once you're satisfied, submit it to the grader.\n",
    "# Import your module\n",
    "#4.4.20 does not work because it is using json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105bcc0-e91d-4df5-8b47-fa945fe2632d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
